{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import frame_parser\n",
    "from src import dataio\n",
    "from src import eval_fn\n",
    "import glob\n",
    "from pprint import pprint\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = 'framenet'\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--language', required=False, help='choose target language', default='ko')\n",
    "parser.add_argument('--model', required=False, help='모델 폴더', default='/disk/frameBERT/cltl_eval/models/ekfn/')\n",
    "parser.add_argument('--eval_model', required=False, help='여러개 모델인지', default='all')\n",
    "parser.add_argument('--test', required=True, help='테스트 데이터')\n",
    "parser.add_argument('--result', required=False, help='결과 저장 폴더', default='/disk/frameBERT/cltl_eval/eval_result/')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.model[-1] != '/':\n",
    "    args.model = args.model+'/'\n",
    "model_name = args.model[:-1]\n",
    "\n",
    "if args.result[-1] == '/':\n",
    "    args.result = args.result[:-1]\n",
    "\n",
    "if model_name.split('/')[-1] == 'best':\n",
    "    model_name = model_name.split('/')[-2]\n",
    "else:\n",
    "    model_name = model_name.split('/')[-1]\n",
    "result_fname = args.result+'/'+model_name+'_to_'+args.test+'.txt'\n",
    "\n",
    "print('##### model:', args.model)\n",
    "print('##### test data:', args.test)\n",
    "print('##### your result file:', result_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koreanframenet import koreanframenet\n",
    "kfn = koreanframenet.interface(version='1.2')\n",
    "\n",
    "en_trn, en_dev, en_tst = dataio.load_data(srl=srl, language='en')\n",
    "\n",
    "ekfn_trn_d, ekfn_tst_d = kfn.load_data(source='efn')\n",
    "jkfn_trn_d, jkfn_tst_d = kfn.load_data(source='jfn')\n",
    "skfn_trn_d, skfn_unlabel_d, skfn_tst_d = kfn.load_data(source='sejong')\n",
    "pkfn_trn_d, pkfn_unlabel_d, pkfn_tst_d = kfn.load_data(source='propbank')\n",
    "\n",
    "ekfn_trn = dataio.data2tgt_data(ekfn_trn_d, mode='train')\n",
    "ekfn_tst = dataio.data2tgt_data(ekfn_tst_d, mode='train')\n",
    "\n",
    "jkfn_trn = dataio.data2tgt_data(jkfn_trn_d, mode='train')\n",
    "jkfn_tst = dataio.data2tgt_data(jkfn_tst_d, mode='train')\n",
    "\n",
    "skfn_trn = dataio.data2tgt_data(skfn_trn_d, mode='train')\n",
    "skfn_unlabel = dataio.data2tgt_data(skfn_unlabel_d, mode='train')\n",
    "skfn_tst = dataio.data2tgt_data(skfn_tst_d, mode='train')\n",
    "\n",
    "pkfn_trn = dataio.data2tgt_data(pkfn_trn_d, mode='train')\n",
    "pkfn_unlabel = dataio.data2tgt_data(pkfn_unlabel_d, mode='train')\n",
    "pkfn_tst = dataio.data2tgt_data(pkfn_tst_d, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = {}\n",
    "tst['ekfn'] = ekfn_tst\n",
    "tst['jkfn'] = jkfn_tst\n",
    "tst['skfn'] = skfn_tst\n",
    "tst['pkfn'] = pkfn_tst\n",
    "\n",
    "print('test data:', args.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srl model: framenet\n",
      "language: en\n",
      "version: 1.2\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/fn1.7_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/fn1.7_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/fn1.7_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/models/joint/36/\n",
      "/disk/frameBERT/models/joint/36/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    }
   ],
   "source": [
    "# Parsing Gold Data\n",
    "\n",
    "def test_model(model_path, masking=True, language='en', test_data='ekfn'):\n",
    "#     torch.cuda.set_device(device)\n",
    "    model = frame_parser.FrameParser(srl=srl,gold_pred=True, model_path=model_path, masking=masking, language=language)\n",
    "    \n",
    "    parsed_result = []\n",
    "    for instance in tst[test_data]:\n",
    "#         torch.cuda.set_device(device)\n",
    "        result = model.parser(instance)[0]\n",
    "        parsed_result.append(result)        \n",
    "#         break\n",
    "        \n",
    "    return parsed_result\n",
    "        \n",
    "# parsed = test_model('/disk/frameBERT/models/joint/36/', language=language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: /disk/frameBERT/models/crosslingual/36\n",
      "srl model: framenet\n",
      "language: en\n",
      "version: 1.2\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/fn1.7_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/fn1.7_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/fn1.7_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/models/crosslingual/36\n",
      "/disk/frameBERT/models/crosslingual/36\n",
      "...model is loaded\n",
      "evaluation is complete: 0hour:0min:0sec\n",
      "{'/disk/frameBERT/models/crosslingual/36': {'arg_f1': 0.5,\n",
      "                                            'arg_precision': 0.5,\n",
      "                                            'arg_recall': 0.5,\n",
      "                                            'frameid': 1.0,\n",
      "                                            'full_f1': 0.6666666666666666,\n",
      "                                            'full_precision': 0.6666666666666666,\n",
      "                                            'full_recall': 0.6666666666666666}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    }
   ],
   "source": [
    "# model_path = '/disk/frameBERT/models/crosslingual/'\n",
    "# models = args.model\n",
    "if args.eval_model == 'all':\n",
    "    models = glob.glob(args.model+'*')\n",
    "else:\n",
    "    models = [args.model]\n",
    "\n",
    "result = {}\n",
    "\n",
    "for model_path in models:\n",
    "    parsed_result = test_model(model_path, language=args.language, test_data=args.test)\n",
    "    frameid, arg_precision, arg_recall, arg_f1, full_precision, full_recall, full_f1 = eval_fn.evaluate(tst[args.test], parsed_result)\n",
    "    \n",
    "    d = {}\n",
    "    d['frameid'] = frameid\n",
    "    d['arg_precision'] = arg_precision\n",
    "    d['arg_recall'] = arg_recall\n",
    "    d['arg_f1'] = arg_f1\n",
    "    d['full_precision'] = full_precision\n",
    "    d['full_recall'] = full_recall\n",
    "    d['full_f1'] = full_f1\n",
    "    result[model_path] = d\n",
    "    print('model:', model_path)\n",
    "    print('test:', args.test)\n",
    "    pprint(d)\n",
    "#     break\n",
    "    \n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/disk/frameBERT/models/crosslingual/36': {'arg_f1': 0.5,\n",
      "                                            'arg_precision': 0.5,\n",
      "                                            'arg_recall': 0.5,\n",
      "                                            'frameid': 1.0,\n",
      "                                            'full_f1': 0.6666666666666666,\n",
      "                                            'full_precision': 0.6666666666666666,\n",
      "                                            'full_recall': 0.6666666666666666}}\n"
     ]
    }
   ],
   "source": [
    "# write file as csv format\n",
    "\n",
    "lines = []\n",
    "lines.append('epoch'+'\\t'+'SenseID'+'\\t'+'Arg_P'+'\\t'+'Arg_R'+'\\t'+'ArgF1'+'\\t'+'full_P'+'\\t'+'full_R'+'\\t'+'full_F1')\n",
    "for m in result:\n",
    "    epoch = m.split('/')[-1]\n",
    "    senseid = str(result[m]['frameid'])\n",
    "    arg_p = str(result[m]['arg_precision'])\n",
    "    arg_r = str(result[m]['arg_recall'])\n",
    "    arg_f1 = str(result[m]['arg_f1'])\n",
    "    full_p = str(result[m]['full_precision'])\n",
    "    full_r = str(result[m]['full_recall'])\n",
    "    full_f1 = str(result[m]['full_f1'])\n",
    "    line = epoch+'\\t'+senseid+'\\t'+arg_p+'\\t'+arg_r+'\\t'+arg_f1+'\\t'+full_p+'\\t'+full_r+'\\t'+full_f1\n",
    "    lines.append(line)    \n",
    "\n",
    "    \n",
    "with open(result_fname, 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(line + '\\n')\n",
    "        \n",
    "print('######')\n",
    "print('\\teval result is written at', result_fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
